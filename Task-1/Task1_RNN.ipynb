{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "892c87d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install miditok\n",
    "#!pip install symusic\n",
    "#!pip install glob\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "012f5709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "from typing import List\n",
    "from collections import defaultdict\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from symusic import Score\n",
    "from miditok import REMI, TokenizerConfig\n",
    "\n",
    "from midi2audio import FluidSynth # Import library\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "from pretty_midi import PrettyMIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "255bf256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Uses 'cuda' if a gpu is detected. Otherwise uses cpu\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Can also set manually\n",
    "#DEVICE = 'cpu'\n",
    "#DEVICE = 'cuda'\n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c60d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"maestro-v3.0.0\"            # change if you unpacked elsewhere\n",
    "meta = pd.read_csv(os.path.join(ROOT, \"maestro-v3.0.0.csv\"))\n",
    "\n",
    "def list_midi_files(split):\n",
    "    paths = meta.loc[meta[\"split\"] == split, \"midi_filename\"]\n",
    "    return [os.path.join(ROOT, p) for p in paths]\n",
    "\n",
    "train_files = list_midi_files(\"train\")        # 962 MIDI files\n",
    "val_files   = list_midi_files(\"validation\")   # 137\n",
    "test_files  = list_midi_files(\"test\")         # 177\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5691ee3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'maestro-v3.0.0\\\\2018/MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--1.midi'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'maestro-v3.0.0\\\\2018/MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--1.midi'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_files[0])\n",
    "train_files[0].encode('utf-8').decode('utf-8')\n",
    "print(train_files[0].encode('utf-8'))\n",
    "str.encode(train_files[0], 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1fe386",
   "metadata": {},
   "source": [
    "Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f30258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from miditok.pytorch_data import DatasetMIDI, DataCollator\n",
    "\n",
    "tokenizer = REMI()  # using defaults parameters (constants.py)\n",
    "train_dataset = DatasetMIDI(\n",
    "    files_paths=train_files,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_len=1024,\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    ")\n",
    "test_dataset = DatasetMIDI(\n",
    "    files_paths=test_files,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_len=1024,\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    ")\n",
    "collator = DataCollator(tokenizer.pad_token_id)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35331c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241, 45)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4794e05e",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c74c73fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(MusicRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        # x: (batch_size, seq_length)\n",
    "        x = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n",
    "        out, hidden = self.rnn(x, hidden)  # out: (batch_size, seq_length, hidden_dim)\n",
    "        out = self.fc(out)  # (batch_size, seq_length, vocab_size)\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7097e0ab",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "831bd37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 3.2964 | Val Loss: 2.8257\n",
      "Epoch 2/20 | Train Loss: 2.6973 | Val Loss: 2.6007\n",
      "Epoch 3/20 | Train Loss: 2.5396 | Val Loss: 2.5278\n",
      "Epoch 4/20 | Train Loss: 2.4392 | Val Loss: 2.4577\n",
      "Epoch 5/20 | Train Loss: 2.3476 | Val Loss: 2.4080\n",
      "Epoch 6/20 | Train Loss: 2.2708 | Val Loss: 2.3961\n",
      "Epoch 7/20 | Train Loss: 2.2010 | Val Loss: 2.3785\n",
      "Epoch 8/20 | Train Loss: 2.1327 | Val Loss: 2.3695\n",
      "Epoch 9/20 | Train Loss: 2.0663 | Val Loss: 2.3833\n",
      "Epoch 10/20 | Train Loss: 1.9955 | Val Loss: 2.4033\n",
      "Epoch 11/20 | Train Loss: 1.9265 | Val Loss: 2.4172\n",
      "Epoch 12/20 | Train Loss: 1.8580 | Val Loss: 2.4365\n",
      "Epoch 13/20 | Train Loss: 1.7882 | Val Loss: 2.4719\n",
      "Epoch 14/20 | Train Loss: 1.7257 | Val Loss: 2.5060\n",
      "Epoch 15/20 | Train Loss: 1.6581 | Val Loss: 2.5525\n",
      "Epoch 16/20 | Train Loss: 1.5921 | Val Loss: 2.6076\n",
      "Epoch 17/20 | Train Loss: 1.5318 | Val Loss: 2.6554\n",
      "Epoch 18/20 | Train Loss: 1.4685 | Val Loss: 2.7075\n",
      "Epoch 19/20 | Train Loss: 1.4081 | Val Loss: 2.7746\n",
      "Epoch 20/20 | Train Loss: 1.3525 | Val Loss: 2.8417\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, val_loader, vocab_size, num_epochs=20, lr=0.001, device=DEVICE):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # --------- Training ---------\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            batch = batch['input_ids'].to(device)  # (batch_size, seq_length)\n",
    "\n",
    "            inputs = batch[:, :-1]\n",
    "            targets = batch[:, 1:]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(inputs)\n",
    "            outputs = outputs.reshape(-1, vocab_size)\n",
    "            targets = targets.reshape(-1)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        # --------- Validation ---------\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch['input_ids'].to(device)\n",
    "\n",
    "                inputs = batch[:, :-1]\n",
    "                targets = batch[:, 1:]\n",
    "\n",
    "                outputs, _ = model(inputs)\n",
    "                outputs = outputs.reshape(-1, vocab_size)\n",
    "                targets = targets.reshape(-1)\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "    embedding_dim = 256\n",
    "    hidden_dim = 512\n",
    "    num_layers = 2\n",
    "\n",
    "    model = MusicRNN(vocab_size, embedding_dim, hidden_dim, num_layers)\n",
    "    train(model, train_loader, test_loader, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecb8e86",
   "metadata": {},
   "source": [
    "Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09fb02fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, start_token, max_length=100, temperature=1.0, device=DEVICE):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    generated = [start_token]\n",
    "    input_token = torch.tensor([[start_token]], device=device)  # (1, 1)\n",
    "\n",
    "    hidden = None\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        output, hidden = model(input_token, hidden)  # output: (1, 1, vocab_size)\n",
    "        output = output[:, -1, :]  # take the last output\n",
    "        output = output / temperature  # adjust randomness\n",
    "\n",
    "        probs = F.softmax(output, dim=-1)  # (1, vocab_size)\n",
    "        next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "        generated.append(next_token)\n",
    "        if next_token == 2 or next_token == 0: # reach end of sequence\n",
    "          break\n",
    "\n",
    "        input_token = torch.tensor([[next_token]], device=device)\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "94898224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated token sequence:\n",
      "[1, 4, 189, 46, 104, 126, 193, 32, 107, 125, 51, 106, 125, 194, 20, 104, 125, 195, 48, 105, 125, 196, 32, 103, 126, 44, 106, 126, 199, 20, 103, 125, 200, 29, 105, 125, 202, 39, 105, 125, 203, 37, 105, 125, 204, 32, 104, 125, 205, 37, 106, 125, 206, 32, 105, 125, 44, 108, 125, 208, 39, 109, 125, 32, 105, 125, 37, 108, 125, 209, 37, 109, 125, 210, 32, 111, 125, 210, 37, 110, 125, 212, 44, 110, 125, 213, 32, 110, 126, 39, 108, 125, 215, 36, 108, 125, 216, 37, 113, 126, 39, 113, 126, 217, 51, 114, 126, 218, 20, 111, 125, 32, 110, 125, 220, 37, 109, 125, 49, 113, 125, 4, 189, 41, 110, 125, 190, 37, 111, 126, 32, 112, 125, 44, 112, 125, 191, 41, 112, 126, 192, 29, 101, 125, 49, 109, 125, 193, 37, 112, 125, 51, 112, 125, 194, 44, 110, 125, 196, 32, 106, 161, 49, 113, 126, 197, 41, 103, 146, 199, 37, 109, 125, 200, 41, 108, 125, 202, 37, 106, 125, 204, 41, 106, 125, 205, 44, 107, 125, 206, 41, 108, 125, 207, 37, 109, 126, 208, 32, 109, 125, 209, 37, 109, 125, 210, 39, 109, 125, 211, 34, 110, 125, 212, 39, 109, 126, 213, 36, 109, 126, 214, 40, 114, 126, 215, 27, 112, 125, 48, 116, 125, 217, 24, 114, 154, 39, 112, 152, 37, 111, 125, 48, 114, 126, 218, 42, 112, 126, 220, 44, 111, 127, 4, 190, 48, 112, 126, 191, 49, 112, 125, 193, 48, 111, 126, 195, 49, 112, 126, 197, 53, 113, 125, 199, 54, 111, 126, 200, 60, 111, 126, 201, 61, 111, 126, 203, 63, 111, 126, 44, 113, 141, 49, 110, 136, 41, 111, 134, 203, 49, 114, 128, 205, 56, 111, 126, 207, 60, 114, 126, 209, 58, 115, 127, 211, 60, 114, 126, 48, 113, 125, 212, 49, 114, 125, 213, 58, 114, 125, 215, 48, 113, 126, 60, 114, 126, 217, 49, 115, 125, 41, 114, 125, 61, 115, 126, 219, 65, 114, 125, 220, 64, 115, 125, 4, 191, 70, 116, 126, 192, 65, 116, 126, 194, 61, 115, 125, 195, 58, 114, 125, 197, 60, 116, 126, 199, 59, 115, 125, 201, 66, 114, 125, 202, 54, 115, 126, 204, 63, 117, 126, 61, 118, 126, 70, 117, 126, 206, 51, 118, 125, 45, 115, 126, 42, 117, 126, 207, 66, 117, 126, 209, 53, 113, 125, 63, 115, 126, 211, 61, 115, 126, 49, 111, 126, 213, 54, 114, 126, 58, 115, 125, 215, 46, 109, 125, 216, 51, 111, 125, 218, 53, 113, 125, 219, 49, 112, 125, 220, 41, 117, 126, 49, 115, 125, 4, 189, 37, 115, 126, 190, 46, 99, 125, 191, 43, 109, 125, 192, 41, 110, 125, 193, 37, 106, 125, 46, 112, 126, 194, 48, 112, 125, 196, 49, 109, 125, 37, 107, 125, 61, 109, 126, 198, 60, 111, 125, 57, 113, 125, 200, 41, 110, 125, 201, 56, 114, 126, 203, 49, 110, 125, 53, 112, 126, 37, 106, 125, 204, 58, 113, 126, 205, 62, 113, 126, 206, 46, 109, 125, 61, 113, 126, 207, 46, 109, 125, 58, 112, 127, 208, 54, 111, 126, 210, 48, 110, 125, 212, 46, 109, 125, 62, 109, 126, 213, 46, 106, 125, 63, 111, 126, 215, 60, 110, 126, 216, 48, 111, 125, 40, 109, 126, 61, 113, 127, 217, 49, 112, 126, 219, 61, 108, 125, 220, 41, 110, 125, 61, 111, 126, 4, 189, 48, 110, 125, 191, 60, 112, 126, 42, 111, 125, 192, 48, 111, 125, 58, 113, 125, 193, 39, 111, 125, 57, 114, 126, 195, 39, 110, 126, 60, 113, 126, 196, 58, 111, 125, 197, 61, 114, 127, 198, 46, 115, 125, 200, 61, 113, 126, 202, 63, 115, 126, 46, 111, 125, 203, 58, 113, 126, 205, 58, 114, 126, 49, 111, 126, 207, 60, 114, 126, 51, 111, 126, 208, 58, 114, 126, 46, 112, 125, 210, 48, 112, 126, 212, 58, 113, 125, 46, 112, 126, 23, 109, 125, 213, 58, 110, 125, 214, 56, 111, 126, 216, 39, 106, 125, 218, 54, 113, 125, 220, 49, 110, 125, 4, 189, 41, 108, 125, 53, 111, 125, 191, 49, 109, 125, 192, 46, 109, 125, 193, 39, 111, 125, 36, 109, 125, 48, 115, 126, 194, 41, 109, 125, 195, 44, 111, 126, 196, 49, 112, 125, 197, 29, 109, 125, 198, 41, 108, 126, 29, 109, 125, 33, 110, 125, 199, 49, 112, 126, 201, 51, 111, 126, 41, 111, 125, 202, 53, 112, 126, 37, 108, 125, 204, 34, 111, 128, 37, 110, 128, 46, 109, 126, 206, 53, 111, 126, 207, 54, 114, 125, 209, 41, 114, 125, 29, 111, 125, 43, 111, 125, 211, 54, 114, 125, 212, 58, 115, 125, 213, 57, 112, 126, 215, 62, 113, 125, 216, 39, 114, 126, 29, 112, 125, 42, 114, 127, 58, 111, 125, 66, 114, 126, 217, 60, 113, 125, 219, 61, 114, 125, 220, 60, 114, 126, 4, 189, 26, 117, 125, 38, 113, 125, 45, 114, 125, 61, 115, 125, 191, 58, 103, 125, 192, 63, 116, 126, 194, 61, 112, 126, 195, 65, 114, 126, 197, 46, 115, 125, 25, 112, 125, 37, 113, 125, 70, 114, 127, 61, 114, 126, 199, 73, 116, 126, 201, 70, 115, 125, 205, 70, 116, 125, 206, 39, 114, 126, 75, 115, 126, 207, 36, 110, 126, 27, 112, 126, 82, 116, 126, 210, 69, 114, 126, 211, 68, 111, 125, 212, 72, 112, 126, 213, 70, 110, 125, 215, 65, 111, 125, 216, 39, 109, 125, 61, 115, 125, 217, 41, 110, 126, 42, 107, 125, 218, 63, 114, 126, 219, 59, 113, 125, 220, 56, 112, 126, 4, 189, 39, 111, 125, 51, 113, 125, 191, 41, 111, 125, 32, 112, 125, 53, 114, 126, 193, 51, 114, 126, 194, 44, 113, 126, 195, 37, 114, 125, 196, 41, 112, 125, 197, 39, 111, 126, 33, 108, 125, 198, 37, 112, 126, 199, 25, 110, 125, 200, 39, 112, 125, 202, 42, 110, 126, 12, 113, 125, 203, 41, 109, 125, 204, 30, 113, 126, 49, 113, 126, 206, 40, 113, 126, 34, 111, 126, 208, 37, 112, 126, 40, 113, 127, 210, 30, 112, 127, 34, 113, 126, 212, 39, 114, 127, 30, 110, 127, 43, 113, 126, 214, 37, 111, 126, 215, 34, 112, 126, 217, 28, 112, 131, 218, 31, 111, 131, 43, 111, 126, 39, 106, 126, 220, 43, 111, 126, 4, 190, 47, 114, 126, 191, 44, 113, 126, 192, 43, 113, 126, 193, 47, 114, 126, 195, 48, 114, 126, 196, 47, 113, 126, 197, 41, 105, 125, 44, 106, 125, 200, 50, 112, 126, 201, 43, 107, 125, 51, 114, 126, 202, 50, 111, 126, 204, 27, 105, 125, 48, 111, 125, 206, 48, 113, 126, 207, 29, 106, 125, 34, 108, 125, 41, 105, 125, 208, 51, 113, 125, 210, 39, 112, 125, 48, 111, 126, 211, 51, 115, 126, 213, 53, 115, 125, 214, 29, 114, 128, 22, 114, 127, 215, 51, 113, 126, 216, 50, 114, 126, 218, 51, 115, 126, 220, 48, 115, 128, 4, 191, 50, 112, 126, 193, 51, 117, 129, 48, 119, 128, 194, 29, 113, 128, 41, 116, 126, 198, 45, 109, 125, 199, 42, 113, 125, 201, 41, 114, 125, 202, 44, 114, 125, 204, 38, 114, 125, 205, 39, 112, 125, 206, 41, 111, 126, 207, 38, 112, 125, 209, 39, 113, 126, 210, 30, 112, 126, 211, 31, 110, 126, 213, 34, 108, 125, 215, 27, 115, 144, 34, 111, 139, 31, 108, 126, 216, 39, 109, 125, 217, 41, 111, 126, 219, 39, 109, 125, 220, 41, 113, 125, 4, 190, 39, 113, 126, 191, 41, 114, 125, 193, 34, 114, 125, 195, 39, 112, 126, 196, 36, 112, 129, 199, 24, 110, 129, 36, 109, 126, 201, 39, 109, 126, 202, 41, 111, 126, 204, 45, 112, 126, 206, 51, 114, 126, 208, 44, 111, 133, 210, 41, 109, 129, 212, 39, 109, 125, 213, 38, 110, 125, 214, 39, 112, 125, 216, 41, 111, 125, 218, 38, 111, 126, 219, 34, 111, 125, 4, 189, 39, 111, 126, 191, 29, 111, 147, 38, 112, 134, 193, 41, 107, 126, 195, 42, 107, 125, 197, 45, 104, 125, 198, 41, 104, 125, 199, 45, 106, 125, 200, 46, 105, 125, 202, 48, 106, 125, 204, 46, 107, 125, 205, 50, 111, 126, 206, 51, 109, 125, 208, 50, 110, 125, 210, 48, 111, 125, 211, 51, 110, 125, 212, 53, 110, 125, 214, 51, 110, 125, 216, 55, 111, 125, 218, 57, 112, 125, 219, 60, 113, 125, 4, 189, 58, 111, 125, 191, 62, 107, 125, 192, 65, 110, 125, 193, 63, 111, 125, 45, 104, 125, 37, 100, 125, 194, 42, 105, 125, 195, 65, 108, 125, 197, 66, 112, 126, 198, 45, 105, 125, 51, 105, 125, 65, 111, 125, 41, 104, 125, 44, 101, 125, 199, 62, 112, 125, 201, 62, 111, 125, 204, 53, 107, 125, 60, 110, 125, 205, 51, 104, 125, 206, 47, 103, 125, 41, 102, 125, 209, 61, 111, 126, 210, 50, 108, 126, 58, 111, 126, 41, 106, 125, 212, 51, 103, 125, 215, 53, 109, 125, 217, 48, 109, 125, 219, 45, 104, 125, 220, 46, 105, 125, 4, 190, 41, 105, 125, 46, 104, 125, 192, 50, 108, 125, 193, 46, 102, 125, 194, 50, 111, 125, 195, 46, 111, 125, 41, 104, 125, 197, 45, 104, 125, 198, 58, 111, 125, 199, 46, 103, 125, 48, 103, 125, 202, 60, 111, 125, 44, 106, 125, 204, 51, 109, 125, 205, 53, 113, 125, 206, 58, 110, 125, 41, 105, 125, 207, 57, 110, 125, 208, 51, 108, 125, 209, 39, 106, 125, 211, 46, 103, 125, 57, 113, 125, 215, 54, 107, 125, 217, 57, 111, 125, 51, 108, 125, 219, 49, 104, 125, 61, 110, 125, 4, 189, 60, 109, 125, 190, 45, 106, 125, 51, 108, 125, 58, 106, 125, 192, 63, 111, 125, 193, 61, 111, 125, 194, 45, 109, 125, 41, 105, 125, 197, 65, 110, 125, 198, 65, 102, 125, 199, 44, 103, 125, 41, 103, 125, 68, 112, 125, 48, 108, 125, 201, 51, 105, 125, 202, 56, 110, 125, 204, 44, 103, 125, 41, 101, 125, 204, 65, 107, 125, 205, 37, 104, 125, 206, 63, 110, 125, 207, 65, 112, 125, 208, 44, 106, 125, 209, 68, 110, 125, 210, 39, 106, 125, 211, 65, 109, 125, 212, 44, 105, 126, 213, 70, 110, 125, 214, 44, 100, 125, 68, 101, 125, 215, 65, 111, 125, 217, 46, 106, 126, 68, 111, 125, 218, 49, 105, 125, 219, 66, 108, 125, 220, 60, 107, 125, 4, 189, 65, 110, 125, 44, 101, 125, 190, 66, 110, 125, 192, 65, 111, 126, 193, 49, 104, 125, 194, 41, 102, 125, 65, 110, 125, 195, 44, 103, 125, 73, 111, 125, 196, 68, 110, 125, 198, 44, 106, 125, 41, 106, 125, 64, 109, 125, 201, 65, 108, 125, 41, 107, 125, 203, 60, 110, 125, 204, 44, 106, 125, 61, 110, 126, 206, 60, 111, 125, 41, 104, 125, 207, 44, 108, 125, 208, 56, 112, 125, 209, 49, 108, 125, 210, 41, 106, 125, 211, 44, 103, 125, 49, 108, 125, 213, 41, 104, 125, 214, 36, 106, 126, 44, 109, 125, 215, 41, 106, 126, 217, 37, 105, 125, 219, 44, 102, 125, 41, 106, 125, 220, 36, 102, 125, 4, 189, 44, 105, 125, 41, 104, 125, 191, 41, 104, 125, 192, 37, 106, 125, 194, 36, 105, 125, 195, 37, 106, 125, 196, 36, 101, 125, 197, 37, 101, 125, 199, 39, 103, 125, 36, 104, 125, 200, 34, 105, 125, 201, 41, 110, 125, 202, 37, 108, 125, 203, 34, 102, 125, 204, 29, 104, 125, 205, 37, 106, 125, 206, 34, 107, 125, 207, 39, 104, 125, 36, 106, 125, 209, 37, 104, 126, 210, 30, 104, 126, 212, 41, 107, 126, 213, 34, 102, 126, 215, 48, 104, 126, 217, 29, 107, 125, 41, 110, 125, 219, 39, 106, 125, 4, 189, 34, 107, 126, 191, 41, 110, 125]\n"
     ]
    }
   ],
   "source": [
    "start_token = tokenizer.special_tokens_ids[1]\n",
    "generated_sequence = sample(model, start_token, max_length=2048)\n",
    "\n",
    "print(\"Generated token sequence:\")\n",
    "print(generated_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f074b3",
   "metadata": {},
   "source": [
    "Convert Midi to Wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "049cfb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_27640\\1455940017.py:3: UserWarning: miditok: The `tokens_to_midi` method had been renamed `decode`. It is now depreciated and will be removed in future updates.\n",
      "  output_score = tokenizer.tokens_to_midi([generated_sequence])\n"
     ]
    }
   ],
   "source": [
    "fs = FluidSynth(\"FluidR3Mono_GM.sf3\") # Initialize FluidSynth\n",
    "\n",
    "output_score = tokenizer.tokens_to_midi([generated_sequence])\n",
    "output_score.dump_midi(f\"rnn.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07fd0fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration (seconds): 36.1875\n",
      "Acoustic Grand Piano: 545 notes\n"
     ]
    }
   ],
   "source": [
    "pretty_midi = PrettyMIDI(\"rnn.mid\")\n",
    "print(\"Duration (seconds):\", pretty_midi.get_end_time())\n",
    "for i, instrument in enumerate(pretty_midi.instruments):\n",
    "    print(f\"{instrument.name or 'Unnamed'}:\", len(instrument.notes), \"notes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
