{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "892c87d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install miditok\n",
    "#!pip install symusic\n",
    "#!pip install glob\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f5709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "from typing import List\n",
    "from collections import defaultdict\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from symusic import Score\n",
    "from miditok import REMI, TokenizerConfig\n",
    "\n",
    "from midi2audio import FluidSynth # Import library\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255bf256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Uses 'cuda' if a gpu is detected. Otherwise uses cpu\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Can also set manually\n",
    "#DEVICE = 'cpu'\n",
    "#DEVICE = 'cuda'\n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c60d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"maestro-v3.0.0\"            # change if you unpacked elsewhere\n",
    "meta = pd.read_csv(os.path.join(ROOT, \"maestro-v3.0.0.csv\"))\n",
    "\n",
    "def list_midi_files(split):\n",
    "    paths = meta.loc[meta[\"split\"] == split, \"midi_filename\"]\n",
    "    return [os.path.join(ROOT, p) for p in paths]\n",
    "\n",
    "train_files = list_midi_files(\"train\")        # 962 MIDI files\n",
    "val_files   = list_midi_files(\"validation\")   # 137\n",
    "test_files  = list_midi_files(\"test\")         # 177\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5691ee3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'maestro-v3.0.0\\\\2018/MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--1.midi'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'maestro-v3.0.0\\\\2018/MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--1.midi'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_files[0])\n",
    "train_files[0].encode('utf-8').decode('utf-8')\n",
    "print(train_files[0].encode('utf-8'))\n",
    "str.encode(train_files[0], 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1fe386",
   "metadata": {},
   "source": [
    "Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f30258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from miditok.pytorch_data import DatasetMIDI, DataCollator\n",
    "\n",
    "tokenizer = REMI()  # using defaults parameters (constants.py)\n",
    "train_dataset = DatasetMIDI(\n",
    "    files_paths=train_files,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_len=1024,\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    ")\n",
    "test_dataset = DatasetMIDI(\n",
    "    files_paths=test_files,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_len=1024,\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    ")\n",
    "collator = DataCollator(tokenizer.pad_token_id)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35331c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241, 45)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4794e05e",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c73fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(MusicRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        # x: (batch_size, seq_length)\n",
    "        x = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n",
    "        out, hidden = self.rnn(x, hidden)  # out: (batch_size, seq_length, hidden_dim)\n",
    "        out = self.fc(out)  # (batch_size, seq_length, vocab_size)\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7097e0ab",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831bd37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 3.3886 | Val Loss: 2.8900\n",
      "Epoch 2/20 | Train Loss: 2.7531 | Val Loss: 2.6252\n",
      "Epoch 3/20 | Train Loss: 2.5753 | Val Loss: 2.5418\n",
      "Epoch 4/20 | Train Loss: 2.4807 | Val Loss: 2.4895\n",
      "Epoch 5/20 | Train Loss: 2.3892 | Val Loss: 2.4358\n",
      "Epoch 6/20 | Train Loss: 2.3119 | Val Loss: 2.4036\n",
      "Epoch 7/20 | Train Loss: 2.2446 | Val Loss: 2.3865\n",
      "Epoch 8/20 | Train Loss: 2.1777 | Val Loss: 2.3736\n",
      "Epoch 9/20 | Train Loss: 2.1124 | Val Loss: 2.3751\n",
      "Epoch 10/20 | Train Loss: 2.0464 | Val Loss: 2.3829\n",
      "Epoch 11/20 | Train Loss: 1.9810 | Val Loss: 2.3998\n",
      "Epoch 12/20 | Train Loss: 1.9148 | Val Loss: 2.4171\n",
      "Epoch 13/20 | Train Loss: 1.8470 | Val Loss: 2.4387\n",
      "Epoch 14/20 | Train Loss: 1.7825 | Val Loss: 2.4785\n",
      "Epoch 15/20 | Train Loss: 1.7208 | Val Loss: 2.5168\n",
      "Epoch 16/20 | Train Loss: 1.6590 | Val Loss: 2.5640\n",
      "Epoch 17/20 | Train Loss: 1.5958 | Val Loss: 2.6059\n",
      "Epoch 18/20 | Train Loss: 1.5385 | Val Loss: 2.6488\n",
      "Epoch 19/20 | Train Loss: 1.4784 | Val Loss: 2.7093\n",
      "Epoch 20/20 | Train Loss: 1.4230 | Val Loss: 2.7504\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, val_loader, vocab_size, num_epochs=20, lr=0.001, device=DEVICE):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # --------- Training ---------\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            batch = batch['input_ids'].to(device)  # (batch_size, seq_length)\n",
    "\n",
    "            inputs = batch[:, :-1]\n",
    "            targets = batch[:, 1:]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(inputs)\n",
    "            outputs = outputs.reshape(-1, vocab_size)\n",
    "            targets = targets.reshape(-1)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        # --------- Validation ---------\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch['input_ids'].to(device)\n",
    "\n",
    "                inputs = batch[:, :-1]\n",
    "                targets = batch[:, 1:]\n",
    "\n",
    "                outputs, _ = model(inputs)\n",
    "                outputs = outputs.reshape(-1, vocab_size)\n",
    "                targets = targets.reshape(-1)\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "    embedding_dim = 256\n",
    "    hidden_dim = 512\n",
    "    num_layers = 2\n",
    "\n",
    "    model = MusicRNN(vocab_size, embedding_dim, hidden_dim, num_layers)\n",
    "    train(model, train_loader, test_loader, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecb8e86",
   "metadata": {},
   "source": [
    "Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fb02fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated token sequence:\n",
      "[1, 4, 205, 30, 102, 129, 207, 58, 107, 133, 214, 46, 99, 127, 218, 42, 103, 130, 58, 109, 129, 4, 195, 34, 102, 126, 196, 54, 111, 129, 201, 49, 101, 125, 202, 37, 101, 126, 204, 58, 108, 129, 205, 42, 101, 125, 212, 53, 108, 130, 213, 25, 101, 126, 217, 42, 102, 126, 218, 37, 100, 125, 4, 195, 47, 105, 127, 39, 99, 128, 35, 100, 127, 196, 41, 103, 128, 206, 44, 100, 129, 41, 97, 130, 207, 39, 97, 128, 213, 58, 108, 128, 27, 100, 128, 42, 102, 127, 46, 102, 127, 219, 56, 111, 129, 4, 189, 56, 111, 128, 41, 103, 127, 39, 104, 127, 191, 37, 101, 131, 192, 58, 112, 126, 41, 106, 128, 195, 56, 111, 128, 199, 54, 110, 130, 200, 49, 100, 129, 42, 100, 128, 51, 100, 130, 201, 46, 101, 128, 206, 54, 109, 128, 207, 46, 102, 126, 54, 102, 127, 209, 42, 99, 128, 46, 100, 131, 215, 54, 107, 140, 46, 102, 127, 30, 99, 127, 49, 99, 126, 4, 189, 37, 99, 129, 195, 41, 100, 129, 53, 107, 127, 37, 99, 129, 196, 46, 95, 126, 205, 51, 102, 130, 206, 42, 98, 128, 30, 98, 128, 210, 49, 96, 128, 219, 52, 103, 131, 220, 24, 99, 130, 13, 97, 129, 45, 97, 130, 4, 196, 47, 103, 126, 206, 49, 101, 128, 208, 37, 100, 126, 41, 100, 127, 47, 105, 129, 212, 45, 107, 125, 215, 49, 108, 126, 217, 45, 107, 127, 219, 53, 113, 127, 37, 108, 126, 46, 110, 126, 4, 191, 54, 112, 128, 194, 21, 108, 129, 45, 109, 127, 200, 49, 111, 129, 203, 37, 101, 126, 41, 101, 125, 207, 54, 112, 130, 208, 45, 105, 127, 212, 56, 111, 129, 213, 46, 104, 127, 218, 53, 111, 125, 42, 105, 125, 49, 102, 125, 4, 190, 25, 104, 125, 49, 108, 125, 194, 53, 110, 129, 195, 38, 102, 125, 51, 107, 127, 199, 25, 102, 126, 203, 49, 108, 131, 204, 44, 103, 130, 208, 37, 104, 126, 41, 102, 126, 210, 49, 111, 126, 212, 30, 104, 125, 214, 53, 112, 125, 218, 25, 105, 128, 219, 49, 108, 140, 4, 191, 25, 103, 126, 193, 39, 104, 125, 37, 105, 125, 196, 53, 109, 131, 46, 102, 125, 201, 47, 105, 132, 37, 102, 127, 202, 39, 101, 128, 42, 98, 127, 206, 41, 103, 125, 209, 53, 109, 137, 37, 102, 128, 41, 99, 128, 214, 47, 104, 125, 219, 41, 102, 126, 220, 37, 103, 126, 49, 100, 125, 4, 192, 46, 104, 129, 34, 99, 129, 196, 27, 100, 127, 198, 54, 108, 127, 202, 29, 102, 126, 205, 54, 107, 132, 206, 46, 98, 127, 210, 30, 96, 129, 212, 54, 106, 130, 216, 49, 103, 127, 219, 37, 104, 125, 4, 192, 53, 111, 130, 41, 102, 129, 197, 30, 103, 127, 37, 102, 128, 53, 109, 137, 203, 46, 104, 125, 205, 53, 110, 129, 206, 37, 100, 127, 209, 51, 104, 125, 212, 53, 110, 130, 32, 103, 129, 217, 51, 109, 129, 53, 109, 130, 220, 24, 103, 129, 4, 193, 47, 107, 130, 199, 53, 108, 129, 200, 41, 101, 128, 205, 51, 110, 129, 211, 44, 102, 129, 30, 100, 129, 39, 97, 129, 219, 53, 109, 146, 44, 99, 129, 4, 194, 41, 101, 125, 37, 100, 125, 196, 44, 101, 125, 202, 41, 101, 128, 53, 109, 133, 203, 47, 100, 128, 209, 53, 108, 137, 41, 99, 131, 37, 97, 127, 213, 25, 97, 130, 219, 53, 106, 130, 4, 193, 37, 100, 125, 194, 41, 100, 129, 203, 53, 108, 133, 208, 25, 101, 129, 216, 44, 100, 127, 4, 196, 37, 100, 131, 197, 37, 94, 126, 202, 44, 101, 132, 208, 30, 102, 133, 209, 42, 102, 128, 211, 46, 106, 127, 215, 47, 103, 125, 44, 103, 125, 220, 30, 102, 128, 4, 189, 59, 109, 130, 191, 47, 102, 129, 194, 37, 102, 130, 199, 62, 109, 129, 35, 102, 129, 200, 51, 105, 125, 201, 44, 102, 126, 203, 59, 109, 127, 205, 41, 104, 129, 53, 108, 129, 208, 56, 109, 125, 42, 102, 129, 211, 54, 109, 125, 212, 56, 109, 129, 217, 30, 102, 127, 218, 44, 98, 127, 54, 97, 127, 4, 192, 39, 103, 128, 196, 58, 108, 128, 46, 101, 128, 199, 42, 103, 127, 37, 101, 136, 201, 54, 110, 127, 204, 53, 108, 125, 206, 53, 108, 129, 207, 49, 105, 127, 34, 100, 131, 32, 101, 129, 213, 42, 105, 125, 218, 53, 109, 126, 46, 105, 125, 30, 102, 125, 219, 49, 102, 125, 4, 192, 30, 105, 126, 51, 110, 130, 193, 54, 112, 132, 196, 42, 104, 129, 202, 30, 103, 127, 51, 106, 131, 49, 102, 128, 46, 99, 127, 205, 42, 104, 130, 210, 58, 112, 150, 211, 42, 103, 127, 30, 100, 129, 54, 108, 143, 51, 101, 152, 215, 37, 102, 129, 219, 42, 102, 129, 4, 192, 39, 102, 128, 196, 37, 101, 130, 201, 58, 109, 132, 30, 102, 130, 46, 101, 127, 42, 104, 127, 202, 49, 95, 129, 206, 56, 109, 133, 53, 104, 131, 44, 99, 125, 29, 102, 132, 212, 41, 102, 127, 217, 56, 105, 127, 218, 53, 103, 127, 31, 101, 148, 30, 102, 134, 48, 104, 127, 4, 190, 46, 103, 131, 195, 58, 108, 128, 196, 51, 101, 129, 39, 101, 133, 37, 100, 128, 42, 101, 129, 201, 56, 109, 128, 53, 104, 129, 202, 37, 100, 128, 42, 101, 128, 39, 100, 125, 208, 56, 109, 134, 212, 39, 102, 130, 35, 100, 130, 39, 99, 127, 213, 44, 98, 127, 220, 37, 101, 131, 56, 108, 126, 4, 189, 25, 98, 130, 191, 49, 102, 128, 196, 56, 105, 130, 44, 99, 130, 201, 25, 101, 130, 202, 37, 99, 130, 204, 53, 107, 129, 208, 25, 100, 130, 209, 59, 108, 129, 210, 44, 102, 129, 216, 41, 97, 125, 217, 41, 104, 125, 49, 104, 129, 4, 189, 25, 103, 126, 193, 37, 101, 130, 56, 108, 126, 193, 49, 97, 125, 196, 44, 104, 130, 53, 108, 128, 37, 101, 129, 201, 51, 107, 125, 202, 49, 106, 130, 205, 32, 102, 130, 210, 53, 107, 129, 211, 37, 104, 125, 41, 102, 125, 44, 102, 125, 214, 51, 108, 125, 215, 49, 109, 125, 25, 102, 126, 41, 104, 125, 217, 49, 109, 125, 218, 37, 102, 127, 41, 103, 125, 4, 190, 54, 110, 127, 39, 106, 125, 42, 102, 125, 34, 102, 129, 195, 51, 109, 131, 42, 101, 129, 49, 102, 128, 30, 102, 129, 201, 49, 105, 129, 207, 32, 100, 166, 24, 101, 126, 208, 56, 109, 131, 210, 49, 100, 125, 213, 56, 107, 125, 41, 100, 130, 215, 37, 99, 129, 217, 56, 107, 125, 218, 53, 102, 133, 219, 32, 93, 126, 4, 190, 41, 99, 130, 44, 96, 125, 191, 53, 106, 130, 197, 44, 102, 129, 32, 99, 129, 202, 41, 101, 129, 205, 53, 108, 128, 208, 44, 104, 130, 37, 97, 129, 213, 42, 103, 129, 51, 108, 126, 217, 53, 107, 125, 51, 102, 126, 4, 191, 17, 104, 127, 192, 66, 109, 131, 196, 53, 102, 131, 200, 44, 99, 128, 203, 37, 100, 130, 41, 96, 128, 208, 32, 100, 128, 209, 65, 109, 126, 210, 53, 99, 125, 214, 41, 103, 129, 65, 111, 126, 53, 106, 125, 220, 65, 111, 125, 53, 104, 125, 4, 190, 65, 111, 125, 191, 53, 104, 125, 197, 65, 110, 130, 198, 25, 103, 127, 205, 71, 109, 133, 68, 105, 134, 212, 37, 99, 127, 218, 41, 102, 125, 4, 191, 44, 100, 125, 70, 111, 126, 193, 58, 101, 125, 197, 46, 102, 132, 202, 70, 111, 128, 37, 100, 128, 204, 58, 105, 126, 210, 42, 101, 129, 37, 96, 128, 70, 111, 125, 215, 73, 110, 130, 216, 9, 101, 128, 220, 37, 99, 130, 4, 195, 66, 110, 129, 30, 103, 125, 198, 42, 103, 128, 202, 58, 109, 125, 204, 58, 111, 125, 206, 30, 102, 125, 58, 110, 127, 215, 46, 103, 129, 42, 102, 130, 4, 190, 37, 102, 132, 191, 59, 112, 125, 192, 53, 107, 125, 193, 47, 106, 125, 195, 41, 105, 125, 49, 107, 126, 196, 53, 111, 125, 202, 47, 108, 129, 41, 105, 128, 30, 106, 129, 207, 53, 110, 129, 29, 102, 130, 212, 53, 108, 127, 44, 102, 130, 216, 54, 112, 125, 47, 107, 125, 4, 189, 53, 111, 125, 49, 105, 125, 41, 104, 125, 194, 58, 112, 131, 54, 108, 125, 200, 53, 103, 125, 201, 53, 107, 125, 203, 65, 113, 134, 204, 53, 100, 126, 213, 61, 109, 132, 214, 34, 99, 133, 215, 53, 99, 132, 37, 96, 132, 220, 44, 97, 125, 4, 189, 37, 99, 128, 194, 59, 111, 129, 47, 104, 125, 200, 46, 104, 127, 201, 54, 109, 129, 202, 42, 101, 128, 206, 58, 110, 126, 207, 46, 101, 129, 54, 107, 125, 209, 56, 108, 126, 210, 54, 108, 126, 212, 25, 104, 127, 213, 53, 107, 134, 218, 32, 99, 129, 4, 190, 53, 107, 127, 191, 51, 107, 134, 197, 32, 104, 128, 200, 42, 104, 129, 201, 46, 104, 129, 205, 37, 100, 128, 209, 53, 108, 127, 42, 102, 128, 212, 51, 109, 125, 213, 48, 107, 125, 217, 53, 107, 128, 4, 189, 51, 109, 133, 196, 48, 105, 127, 39, 100, 129, 34, 99, 129, 201, 42, 102, 128, 205, 37, 100, 130, 53, 110, 148, 206, 41, 102, 127, 209, 44, 102, 125, 212, 53, 109, 125, 41, 102, 125, 214, 37, 103, 125, 217, 53, 111, 136, 44, 106, 129, 4, 190, 41, 103, 130, 195, 53, 110, 128, 34, 101, 126, 37, 100, 129, 196, 54, 109, 125, 197, 53, 108, 125, 202, 35, 102, 129, 53, 108, 125, 203, 59, 93, 143, 213, 53, 103, 130, 215, 37, 98, 125, 4, 190, 56, 105, 139, 36, 100, 127, 197, 49, 102, 125, 34, 101, 125, 203, 47, 100, 126, 208, 37, 100, 127, 42, 99, 127, 213, 53, 105, 125, 219, 30, 101, 125, 220, 54, 106, 145, 4, 189, 51, 99, 134, 42, 99, 134, 197, 42, 102, 129, 202, 46, 102, 125, 208, 51, 103, 131, 210, 30, 101, 126, 215, 42, 99, 126, 46, 103, 128, 219, 59, 110, 134, 220, 37, 100, 131, 39, 100, 131, 4, 195, 58, 109, 136, 196, 46, 99, 125, 201, 37, 100, 125, 203, 42, 100, 130, 208, 58, 109, 125, 212, 41, 100, 125, 214, 58, 110, 128, 219, 44, 100, 127, 4, 192, 58, 109, 134, 18, 103, 125, 197, 51, 107, 127, 200, 34, 101, 128, 201, 22, 100, 129, 202, 54, 108, 152, 208, 42, 101, 127, 211, 46, 105, 126, 215, 42, 102, 128, 46, 103, 127, 4, 189, 58, 110, 130, 27, 103, 127, 47, 104, 130, 195, 58, 108, 136, 200, 46, 100, 126, 204, 37, 99, 128, 51, 104, 130, 207, 47, 104, 126, 213, 56, 109, 127, 47, 101, 128, 219, 30, 103, 126, 59, 109, 139, 4, 193, 58, 109, 128, 194, 46, 101, 128, 200, 61, 112, 128, 30, 102, 126, 42, 101, 126, 206, 58, 111, 129, 49, 102, 126, 212, 35, 102, 130, 23, 103, 128, 218, 60, 110, 144, 4, 190, 39, 102, 128, 196, 37, 99, 129, 197, 47, 104, 126, 201, 44, 103, 125, 207, 68, 110, 130, 32, 103, 127, 211, 42, 103, 128, 215, 68, 110, 131, 44, 103, 131, 4, 190, 66, 111, 130, 192, 45, 101, 130, 199, 42, 100, 130, 37, 102, 130, 201, 66, 111, 126, 209, 65, 110, 132, 42, 102, 130, 37, 102, 126, 219, 65, 110, 134, 47, 102, 125, 53, 103, 126, 4, 193, 66, 108, 130, 30, 102, 130, 194, 39, 99, 129, 198, 61, 106, 128, 204, 66, 113, 127, 34, 102, 126, 58, 104, 126, 210, 49, 103, 129, 214, 65, 112, 129, 35, 101, 129, 215, 54, 96, 128, 4, 190, 44, 103, 128, 193, 66, 109, 128, 37]\n"
     ]
    }
   ],
   "source": [
    "def sample(model, start_token, max_length=100, temperature=1.0, device=DEVICE):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    generated = [start_token]\n",
    "    input_token = torch.tensor([[start_token]], device=device)  # (1, 1)\n",
    "\n",
    "    hidden = None\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        output, hidden = model(input_token, hidden)  # output: (1, 1, vocab_size)\n",
    "        output = output[:, -1, :]  # take the last output\n",
    "        output = output / temperature  # adjust randomness\n",
    "\n",
    "        probs = F.softmax(output, dim=-1)  # (1, vocab_size)\n",
    "        next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "        generated.append(next_token)\n",
    "        if next_token == 2 or next_token == 0: # reach end of sequence\n",
    "          break\n",
    "\n",
    "        input_token = torch.tensor([[next_token]], device=device)\n",
    "\n",
    "    return generated\n",
    "\n",
    "start_token = tokenizer.special_tokens_ids[1]\n",
    "generated_sequence = sample(model, start_token, max_length=1024)\n",
    "\n",
    "print(\"Generated token sequence:\")\n",
    "print(generated_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f074b3",
   "metadata": {},
   "source": [
    "Convert Midi to Wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049cfb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_13864\\1080284856.py:5: UserWarning: miditok: The `tokens_to_midi` method had been renamed `decode`. It is now depreciated and will be removed in future updates.\n",
      "  output_score = tokenizer.tokens_to_midi([generated_sequence])\n"
     ]
    }
   ],
   "source": [
    "fs = FluidSynth(\"FluidR3Mono_GM.sf3\") # Initialize FluidSynth\n",
    "\n",
    "output_score = tokenizer.tokens_to_midi([generated_sequence])\n",
    "output_score.dump_midi(f\"rnn.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d495e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmidi_to_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgenerated_maestro_sample.mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrnn.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m display(Audio(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrnn.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\midi2audio.py:46\u001b[0m, in \u001b[0;36mFluidSynth.midi_to_audio\u001b[1;34m(self, midi_file, audio_file)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmidi_to_audio\u001b[39m(\u001b[38;5;28mself\u001b[39m, midi_file, audio_file):\n\u001b[1;32m---> 46\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfluidsynth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-ni\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msound_font\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmidi_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-F\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-r\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_rate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\torch-gpu\\lib\\subprocess.py:345\u001b[0m, in \u001b[0;36mcall\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall\u001b[39m(\u001b[38;5;241m*\u001b[39mpopenargs, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run command with arguments.  Wait for command to complete or\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    timeout, then return the returncode attribute.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;124;03m    retcode = call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 345\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    347\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m p\u001b[38;5;241m.\u001b[39mwait(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\torch-gpu\\lib\\subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[0;32m    967\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mc:\\Users\\PC\\anaconda3\\envs\\torch-gpu\\lib\\subprocess.py:1456\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1454\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1455\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1456\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1457\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1458\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1466\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1470\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1471\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1472\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1473\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "fs.midi_to_audio(\"generated_maestro_sample.mid\", \"rnn.wav\")\n",
    "display(Audio(\"rnn.wav\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
