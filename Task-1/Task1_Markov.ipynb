{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b35a165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import random\n",
    "from typing import List\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from symusic import Score\n",
    "from miditok import REMI, TokenizerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e52e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"maestro-v3.0.0\"            # change if you unpacked elsewhere\n",
    "meta = pd.read_csv(os.path.join(ROOT, \"maestro-v3.0.0.csv\"))\n",
    "\n",
    "def list_midi_files(split):\n",
    "    paths = meta.loc[meta[\"split\"] == split, \"midi_filename\"]\n",
    "    return [os.path.join(ROOT, p) for p in paths]\n",
    "\n",
    "train_files = list_midi_files(\"train\")        # 962 MIDI files\n",
    "val_files   = list_midi_files(\"validation\")   # 137\n",
    "test_files  = list_midi_files(\"test\")         # 177\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85988d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'maestro-v3.0.0\\\\2018/MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--1.midi'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'maestro-v3.0.0\\\\2018/MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--1.midi'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_files[0])\n",
    "train_files[0].encode('utf-8').decode('utf-8')\n",
    "print(train_files[0].encode('utf-8'))\n",
    "str.encode(train_files[0], 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd780ad",
   "metadata": {},
   "source": [
    "Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf0b0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\miditok\\tokenizations\\remi.py:88: UserWarning: Attribute controls are not compatible with 'config.one_token_stream_for_programs' and multi-vocabulary tokenizers. Disabling them from the config.\n",
      "  super().__init__(tokenizer_config, params)\n"
     ]
    }
   ],
   "source": [
    "config = TokenizerConfig(num_velocities=1, use_chords=False, use_programs=True)\n",
    "tokenizer = REMI(config)\n",
    "tokenizer.train(vocab_size=1000, files_paths=train_files)\n",
    "tokenizer.save(\"tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6637a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIDIDataset(Dataset):\n",
    "    def __init__(self, file_paths: List[str], tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.file_paths = file_paths\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        midi = Score(self.file_paths[idx])\n",
    "        tokens = self.tokenizer(midi)\n",
    "        return np.array(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eda6d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MIDIDataset(train_files, tokenizer)\n",
    "test_dataset = MIDIDataset(test_files, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SecondOrderMarkovChain:\n",
    "    def __init__(self):\n",
    "        self.transitions = defaultdict(lambda: defaultdict(int))\n",
    "        self.probabilities = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    def train(self, train_loader):\n",
    "        for sequence in train_loader:\n",
    "            sequence = sequence[0].numpy().astype(int)\n",
    "            for i in range(len(sequence) - 2):\n",
    "                state1, state2 = sequence[i], sequence[i + 1]\n",
    "                next_state = sequence[i + 2]\n",
    "                self.transitions[(state1, state2)][next_state] += 1\n",
    "\n",
    "        for (state1, state2), next_states in self.transitions.items():\n",
    "            total = sum(next_states.values())\n",
    "            for next_state, count in next_states.items():\n",
    "                self.probabilities[(state1, state2)][next_state] = count / total\n",
    "        return self.probabilities\n",
    "\n",
    "    def generate(self, test_sequence, num_predictions=1):\n",
    "        test_sequence = test_sequence[0].numpy().astype(int)\n",
    "        results = [test_sequence[0], test_sequence[1]]\n",
    "        for i in range(1000):\n",
    "            if (results[-2], results[-1]) not in self.probabilities:\n",
    "                break\n",
    "            else:\n",
    "                probs = self.probabilities[(results[-2], results[-1])]\n",
    "                states = list(probs.keys())\n",
    "                probabilities = list(probs.values())\n",
    "                if not states:\n",
    "                    break\n",
    "                try:\n",
    "                    predictions = np.random.choice(states, size=num_predictions, p=probabilities)\n",
    "                except:\n",
    "                    break\n",
    "                results.append(predictions[0])\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82841ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SecondOrderMarkovChain()\n",
    "model.train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3816d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for test_sequence in test_loader:\n",
    "    predictions.append(model.generate(test_sequence))\n",
    "    break\n",
    "for i, prediction in enumerate(predictions):\n",
    "    output_score = tokenizer.decode(torch.Tensor(prediction))\n",
    "    output_score.dump_midi(f\"{i}.mid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
